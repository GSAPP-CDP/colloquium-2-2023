---
student: Yilin Wang
layout: blank.liquid
tags:
- students
---

<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">  
  <meta name="description"
  content="Student work from Colloquium 1 of the Columbia GSAPP CDP Program in 2023." />
  <link rel="icon" href="https://gsapp-cdp.github.io/colloquium-1-2023/favicon.ico" sizes="any">
  <link rel="icon" href="https://gsapp-cdp.github.io/colloquium-1-2023/favicon.svg" type="image/svg+xml">
  <link href="https://gsapp-cdp.github.io/colloquium-1-2023/base.css" rel="stylesheet" />
  <link href="https://gsapp-cdp.github.io/colloquium-1-2023/main.css" rel="stylesheet" />
  <link href="https://gsapp-cdp.github.io/colloquium-1-2023/colloquium1.css" rel="stylesheet" />

  <link href="mystyle.css" rel="stylesheet" />

  <title>Yilin Wang</title>
</head>

<body>
  <header class="container">
    <div class="header-context">
      <div class="h2">
        <a class="fade" href="https://www.arch.columbia.edu/programs/15-m-s-computational-design-practices"
          target="_blank">Columbia GSAPP</a>
      </div>
    </div>

    <div class="header-title">
      <div class="h1">
        <a class="fade" href="/">Computational Design Practices</a>
      </div>
      <div class="h2">GSAPP CDP 2023-4 Colloquium II</div>
    </div>

    <div class="header-nav">
      <div class="h2">
        <a class="fade" href="/about">About</a>
      </div>
    </div>
  </header>

  <main>
    <div class="container">

      <div class="post">
        <div class="post-header">
          <div class="post-title">
            <h1>Yilin Wang</h1>
          </div>
        </div>

        <div class="post-body project content">
          <!-- ALL WORK SHOULD BE CONTAINED HERE. -->

          <div class="toc full">
            <h2>Table of Contents</h2>
            <ul>
              <li><a href="#assignment-1">1 &ndash; Capstone Project Review2</a></li>
              <!-- <li><a href="#assignment-2">2 &ndash; Idea2</a></li> -->
              <!-- <li><a href="#assignment-3">3 &ndash; Idea3</a></li> -->

            </ul>
          </div>

          <div class="full assignment">
            <h1 id="assignment-1">1 &ndash; Capstone Project Idea</h1>
            <h2>Urban Morphology Generator responsive to local climate by GAN</h2>
            
          </div>

          <div class="half"
            <img src="pocket park examples.png">
          </div>

          <div class="full">
            <h2>Research Question and Research Gap</h2>
            <p>
              The realm of computational urban design (CUrbD) is multifaceted, with designs shaped by factors like 
              street block shape, orientation, program, density, and greenery. While micro-climate considerations 
              usually come into play during outcome evaluation, their potential as adaptive factors in initial stages 
              is often overlooked.
            </p>

            <p>
              Current CUrbD approaches employing GANs, especially models like pix2pix, primarily predict urban texture 
              and imageability, focusing on visual representation due to the 2D limitations of these models. Meanwhile
              the problem of AI is that it could only generates believable images instead of understanding them, not 
              even to say automate our design process.
            </p>

            <p>
              This raises the pivotal questions: Can we seamlessly integrate AI into adaptive urban morphology planning 
              grounded in local climate systems? And, is it possible to fully automate this design process, emphasizing 
              adaptive design over mere visual representation? Can we redefine the CUrbD framework by using climate 
              data (GIS images) as initial inputs, allowing urban morphology to dynamically respond to local climate 
              variations?
            </p>
            
            <h2>Computational tools and design methods</h2>
            <p>
              Data Collection & Preprocessing:  I'm focusing on obtaining meteorological information and city plan images from major cities around the world. The rationale behind this selection is twofold:

              Diverse Climates: By targeting a range of cities, the dataset will encompass a broad spectrum of climatic conditions, ensuring that the GAN model is trained with comprehensive and diverse information.
              
              Urban Complexity: Major cities typically exhibit complex urban structures, which would provide a more challenging and rich dataset. This would test the efficacy of the GAN model in predicting urban morphologies across varied urban layouts.

            </p>
            <p>
              Machine Learning Models: pix2pix model.By feeding the preprocessed GIS images into this model, 
              the aim is to transform these 2D climate representations into predicted urban layouts that are inherently 
              adaptive to the depicted climates.

            </p>
            <p>
              Generative Design Integration: After the machine learning phase, Grasshopper will be instrumental in the 
              responsive generation of 3D urban models. This tool will be employed to extract 3D data from the 2D 
              outcomes produced by the GAN, leading to the creation of adaptive urban morphologies that not only 
              visually represent but functionally respond to the local climate conditions.



            </p>
          </div>

          <div class="half">
            <h2>related precedent1</h2>
            <p>
              DeepScope is a platform that allows designers to test multiple urban designs and observe the Image of 
              the City in real time. 

            </p>

            <p>
              Inspired by Kevin Lynch’s The Image of the City and The View from the Road, Deepscope helps designers 
              think about urban imageability: readability, continuity, legibility, image of the city.

            </p>

            <p>
              method & process:1.With each design iteration, a 3D streetscape model is created; 2.the model is fed into 
              a DCGAN neural network; 3.that generates a realistic street-view visualization.

            </p>
          </div>

          <div class="half">
            <img src="1101/deep_question.png">
            
            
          </div>

          <div class="half">
            <img src="1101/deep method.png">
            
            
            
          </div>

          <div class="half">
            <img src="1101/Deep method2.jpg">
            
          </div>
          

          <div class="half">
            
            <h2>related precedent2</h2>
            <p>
              KPF UI utilized its interactive tool Scout and developed a ‘digital twin’ to help understand how the 
              fictional rust-belt city of Leeside could adapt its built environment to become a climate haven for 
              climate migrants from the coasts of the United States by the year 2040.

            </p>

            <p>
              method & process: 1.To analyze conditions in Rust Belt cities to create the fictional conditions of 
              Leeside (1mile * 1mile); 2.To look into the physical characteristics of rust- belt city: street grid, 
              building height, lot size etc; 3. To define the parameters that people can control through digital twin 
              by Scout.

            </p>
            
          </div>

          <div class="half">
            <img src="1101/leeside2.png">
          </div>

          <div class="full">
            <img src="1101/leeside1.png">
          </div>

          <div class="half">
            
            <h2>Data Exploration and pix2pix algorithm</h2>
            <p>
              1.Local Climate mapping data: From World Urban Database and Access Portal Tools (WUDAPT) webite, to download
              satellite raster data.
            </p>
            <p>
              2.paired urban morphology(building outline, green, water, street) of LCP maps from Mapbox Streets v7 and 
              combine building heights data from OSM.
            </p>
            <p>
              <img src="1101/logic1.png">
            </p>

            
          </div>

          <div class="half">
            <img src="1101/pix2pix2.png">
          </div>

          <div class="half">

          <div class="half">
            <img src="1101/lcz map.png">
          </div>
  
          
          </div>
          <div class="half">
            <img src="1101/mapbox1.png">
          </div>


          <div class="half">
            
            <h2>The process of responsive generation</h2>
            <p>
              After traing pix2pix model, partial 3D models can be constructed in Grasshopper from those generated urban plans.  
            </p>

            <p>
              3D models capable of swiftly responding to alterations in Local climate offered promising potential for 
              applications in further local climate research. In the right image, when local climate map is modified,
              the changes in generated plans and 3D morphology are also occured. 
            </p>

            <p>
              To sum up, the project proposes a design framework for generating urban 3D morphology that can rapidly responds to local climate
              changes. Due to the challenges associated with obtaining high-definition remote-sensing images and the 
              limitation of traditional 3D platform in dynamically generating 3D models, the GAN training methods combining
              local climate data and urban morphology is a innovative way to predict 3D models responsively and rapidly. 
            </p>

            
          </div>
          <div class="half">
            <img src="1101/responsive method.jpg">
          </div>

          

          <!-- <div class="full assignment">
            <h1 id="assignment-2">2 &ndash; Idea2</h1>
            <h2>Generate cities from cities</h2>
            <p></p>
          </div>

          <div class="full">
            <h2>Research Question</h2>
            <p>
              How can the pix2pix GAN, trained on urban satellite imagery, assist designers in generating 
              prospective urban layouts for areas under development or transformation?
            </p>
            
            <h2>Computational tools and design methods</h2>
            <p>
              Data Collection & Preprocessing: Utilizing urban satellite imagery, specifically focusing on the patterns of differnet varieties of 
              urban spaces.

            </p>
            <p>
              ML - pix2pix: Implementing and training a pix2pix GAN that learns the characteristics of these urban spaces
              from the collected images.
            </p>

            <p>
              Design Generation & Visualization(in GH): Applying the trained model to images of areas under development, generating and visualizing 
              potential urban layouts that follow the learned patterns.
            </p> 
          </div>


          <div class="half">
            <img src="1005/i2_pix2pix.png">
            <img src="1005/i2_city_scope1.png">
            <img src="1005/i2-city_scope2.png">
            
            
          </div>

        

          <div class="half">
            <h2>Related Precedents</h2>

            <p>
              pix2pix Projects: Existing applications of pix2pix in image-to-image translation tasks, particularly those related to spatial or 
              architectural design. These GAN algorithms nowadays are quite mature.
            </p>

            <p>
              MIT media lab: The Deep Image of the City: the project utilizes GANs to create deep images of cities, 
              which are essentially synthesized representations of urban areas that don't necessarily exist in reality but are plausible 
              based on the learned patterns and features from real urban imagery. 
            </p>

            <h2>Data for Exploration</h2>

            <p>
              Collection of diverse urban satellite images, preferably annotated or categorized based on the urban planning variety(for example, the road, natural condition), 
              to train the pix2pix model effectively.
            </p>

            <h2>Project Scales</h2>
            <p>
              While initial tests may focus on specific districts or areas within cities, the methodology can be also applied to villages(for example, traditional villages in China)
            </p>

            <h2>Sketches and Audiences</h2>
            <p>
              Sketches will depict the workflow from satellite image input, pix2pix processing, to generated urban layout output and visualize the 2d images in 3d way.
              The target audience includes urban designers, architects, and city planners as well as public.
            </p>

            <img src="1005/i2-sketch1.png">
            <img src="1005/i2_sketch2.png">
            <img src="1005/i2_sketch3.jpg">


          </div>

          <div class="half">
            <img src="">
          </div>

        

          <div class="full assignment">
            <h1 id="assignment-3">3 &ndash; </h1>Idea3
            <h2> Research Question: Can we develop architectural elements that adapt in real-time to environmental changes, using Machine Learning 
              and environmental sensors?</h2>
            <p></p>
          </div>

          <hr>

          <div class="half">
            <img src="">
          </div>

          <div class="half">
            <img src="">
          </div>

          <hr>

          <div class="full">
            <h2>Computational Tools and Design Methods</h2>

            <p>
              Data Collection & Preprocessing: Implement environmental sensors to gather real-time data on factors like temperature, humidity, 
              light intensity, and air quality.
            </p>

            <p>
              Responsive Architectural Elements: Develop elements like dynamic facades, adjustable louvers, or smart windows that react to the 
              analyzed data, adapting their configurations to maintain interior comfort and energy efficiency.
            </p>

          

          </div>

          

          <div class="half">
            <img src="0927//I3-Autodesk.png">
            <img src="0927//I1-Autodesk.png">


    

          </div>

          

          <div class="half">
            <h2>Data for Exploration</h2>
            <p>
              Sensors will continuously gather environmental data. Ensure accessibility to this data stream for analysis and response triggering 
              in the architectural elements.
            </p>
            <h2>Project Scale</h2>
            <p>
              The project can be applicable to single architectural elements or even entire building facades,etc.
              
            </p>

            <h2>related precedents</h2>
            <p>
              Autodesk Project Dasher employs environmental sensors to gather continuous data on various parameters like 
              temperature, humidity, occupancy, and energy consumption. This sensor-derived data is then dynamically mapped onto the building's 3D 
              BIM model. Through this integration, Project Dasher provides a comprehensive, real-time overview of the building's performance and 
              environmental conditions, enabling architects, engineers, and facility managers to understand and optimize the operation of buildings 
              effectively.
              
            </p>
          </div> -->

          

        </div>
      </div>

      <footer></footer>
    </div>
  </main>
</body>

</html>

